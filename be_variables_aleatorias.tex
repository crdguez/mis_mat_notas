%\documentclass[11pt]{beamer}
\documentclass[11pt,handout]{beamer}
\usetheme{Boadilla}
%\usetheme{metropolis}

\usecolortheme{crane}


\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}

\usepackage{hyperref}
\usepackage{graphicx}
\usepackage[spanish]{babel}
\graphicspath{{./img/}}

\usepackage{pgf,tikz}

\usetikzlibrary{shapes, calc, shapes, arrows, math, babel, positioning}
\newcommand{\degre}{\ensuremath{^\circ}}
\usepackage{pgf,tikz,pgfplots}
\pgfplotsset{compat=1.15}
\usepackage{mathrsfs}
\usetikzlibrary{arrows}

%\author{}
\title{Variables aleatorias}

\setbeamercovered{transparent} 
\setbeamertemplate{navigation symbols}{} 
\logo{} 
%\institute{} 
\date{} 
\author{Dep. de Matemáticas}
%\subject{} 
\titlegraphic{\includegraphics[width=0.2\columnwidth]{header_right}}
\begin{document}

\begin{frame}
\titlepage
\end{frame}

%\begin{frame}
%\tableofcontents
%\end{frame}

\begin{frame}{Variables aleatorias y distribuciones de probabilidad}
\begin{block}{Finalidad:} Abstraer matemáticamente un tipo de experimento aleatorio. Y, con ello, poder estimar de manera teórica lo que sucedería de manera experimental mediante una estadística.
\end{block}

\pause

\begin{block}{¿Cómo?:} Mediante variables aleatorias y distribuciones de probabilidad asociadas a esas variables

\end{block}


\end{frame}

\begin{frame}{Variables aleatorias}
\begin{block}{}
Una variable aleatoria es una función que a cada suceso
elemental de un espacio muestral le asigna un número. Para hacer referencia a las variables se usan las letras: $X$, $Y$, ...
\end{block}
\end{frame}

\begin{frame}{Variables aleatorias}
\begin{block}{Ejemplo:}
Sea el experimento aleatorio “lanzar un dado”: El espacio muestral lo componen las 6 caras del dado. Podemos asignar la variable $X$ que a cada cara le asocia el número que represente su cara.
\end{block}
\begin{center}
\begin{tabular}{ccc}
 & $X$ &  \\
Suceso &  &  $x_i$\\ \hline 
Cara 1 & $\rightarrow$ & 1 \\ 
Cara 2 & $\rightarrow$ & 2 \\ 
Cara 3 & $\rightarrow$ & 3 \\ 
Cara 4 & $\rightarrow$ & 4 \\ 
Cara 5 & $\rightarrow$ & 5 \\ 
Cara 6 & $\rightarrow$ & 6 \\ 
\end{tabular} 
\end{center}
\end{frame}


\begin{frame}{Variables aleatorias}
\begin{block}{Ejemplo:}
Sea el experimento compuesto lanzar dos monedas. Podemos asignar la variable aleatoria:
\end{block}
\begin{center}
\emph{Y = \{Número de caras\}} \\
\begin{tabular}{ccc}
 & $Y$ &  \\
Suceso &  &  $y_i$\\ \hline 
C,C & $\rightarrow$ & 2 \\ 
C,X & $\rightarrow$ & 1 \\ 
X,C & $\rightarrow$ & 1 \\ 
X,X & $\rightarrow$ & 0 \\ 
\end{tabular} 
\end{center}
\end{frame}




\begin{frame}{Tipos de variables aleatorias}
\begin{itemize}[<+->]
    \item{Discretas:} Toman un número finito o numerable de valores. \textbf{Ejemplo de variables discreta:} Sea la \emph{X =“El número de caras al lanzar dos dados”}. Los valores posibles son 0, 1 o 2 (que es un conjunto finito de datos, en concreto 3 datos)
\item{Continuas:} Toman valores en un rango continuo. \textbf{Ejemplo:} \emph{X = “Distancia al centro de la diana medida desde la posición en que cae un dardo lanzado por un tirador experto” }. En este caso la variable puede tomar cualquier valor en el rango entre 0 y el radio de la diana 
\end{itemize}

\end{frame}

\begin{frame}{Distribuciones de probabilidad}
Llamaremos Distribución de probabilidad a la relación entre los valores de la variable y sus probabilidades.

Estas relaciones se pueden indicar mediante el uso de funciones. El tipo de función y su tratamiento es diferente según las variables sean discretas o continuas.

Veamos algunas distribuciones:
\end{frame}


\begin{frame}
{Distribución uniforme discreta}

Sea la variable \emph{X = “Número obtenido al lanzar una dado”}\\
A cada valor de la variable podemos asignarle su probabilidad:

%\begin{center}
%\begin{tabular}{ccc}
% & $P(X)$ &  \\
%Suceso &  &  $y_i$ \\ \hline 
%1 & $\rightarrow$ & \frac{1}{6} \\ 
%2 & $\rightarrow$ & \frac{1}{6} \\ 
%3 & $\rightarrow$ & \frac{1}{6} \\ 
%4 & $\rightarrow$ & \frac{1}{6} \\ 
%5 & $\rightarrow$ & \frac{1}{6} \\ 
%6 & $\rightarrow$ & \frac{1}{6} \\ 
%\end{tabular} 
%\end{center}

\begin{center}
\begin{tabular}{ccc}
 & $P(X)$ &  \\
$x_i$ &  &  $P(x_i)$\\ \hline 
1 & $\rightarrow$ & $\tfrac{1}{6}$ \\ 
2 & $\rightarrow$ & $\tfrac{1}{6}$ \\ 
3 & $\rightarrow$ & $\tfrac{1}{6}$ \\ 
4 & $\rightarrow$ & $\tfrac{1}{6}$ \\ 
5 & $\rightarrow$ & $\tfrac{1}{6}$ \\ 
6 & $\rightarrow$ & $\tfrac{1}{6}$ \\ 
\end{tabular} 
\end{center}

Podemos representar la relación anterior mediante una función:

%$$f\colon \begin{array}{lc} 
%         & X \rightarrow Y \\ 
%         & x \mapsto f(x)=\frac{x-1}{2} 
%         \end{array}$$
%
%
%$$f\colon \begin{array}{>{\displaystyle}l} 
%          X \rightarrow Y \\ 
%          x\mapsto f(x)=\frac{x-1}{2} 
%         \end{array}$$

$$P\colon \begin{array}{ll} 
          X \rightarrow \mathbb{R} \\ 
          x_i\mapsto P(X=x_i)=\frac{1}{n} 
         \end{array}$$


A este tipo de distribución se le llama \textbf{uniforme discreta}.
\end{frame}

\begin{frame}
{Distribución Binomial}
\paragraph{Ejemplo:} Queremos calcular las probabilidades de que al lanzar 5 monedas, obtengamos tres caras.
Un suceso que cumple el enunciado es:
$$S_1=\left\lbrace C,C,C,X,X \right\rbrace$$
Teniendo en cuenta que lanzar cada moneda son experimentos independientes, la probabilidad de ese suceso será:
%$$P\left(S_1\right)=P\left(C_1\right)\cdot P\left(C_2 C_1 \right)$$
\begin{eqnarray*}
P\left(S_1\right) & = &P\left(C_1\right)\cdot P\left(C_2 | C_1 \right)\cdot ... \cdot P\left(X_5 | C_1 \cap C_2  \cap C_3  \cap X_4   \right)= \\ &  = & P\left(C_1\right)\cdot  P\left(C_2\right) \cdot P\left(C_3\right) \cdot P\left(X_4\right) \cdot P\left(X_5\right)= \\
& = & P\left(C\right)^3\cdot  P\left(X\right)^2
\end{eqnarray*}

Como la probabilidad de que una moneda sea cara es $\frac{1}{2}$ y la de que sea cruz también:

$$P\left(S_1\right)=\left(\frac{1}{2}\right)^3\cdot  \left(\frac{1}{2}\right)^2$$

Ahora bien, habrá tantos sucesos que cumplan el enunciado como combinaciones de 5 elementos tomados de 3 en 3. Por tanto la probabilidad de que salgan 3 caras será:

$$P\left(Salgan \ 3 \ caras\right)=\binom{5}{3}\left(\frac{1}{2}\right)^3\cdot  \left(\frac{1}{2}\right)^2$$

\end{frame}

\begin{frame}{Distribución Binomial}

Al experimento "lanzar 5 monedas" le asignamos la variable "número de caras obtenidas", podemos determinar la probabilidad mediante la siguiente función.

$$P\colon \begin{array}{l} 
          X \rightarrow \mathbb{R} \\ 
          k\mapsto P(X=k)=\binom{5}{k}\left(\frac{1}{2}\right)^k\cdot  \left(\frac{1}{2}\right)^{5-k} 
         \end{array}$$

Esto es un ejemplo de distribución binomial de tamaño $5$ y probabilidad $0.5$ .
\end{frame}


\begin{frame}{Distribución Binomial}
Realizando los cálculos para $k = 1,...,5 $, la distribución de probabilidad de $X$ que resulta es:
\begin{columns}
\begin{column}{0.3\textwidth}
\begin{center}
\begin{tabular}{ccc}
 & $P(X)$ &  \\
$x_i$ &  &  $P(x_i)$\\ \hline 
0 & $\rightarrow$ & $0.03125$ \\ 
1 & $\rightarrow$ & $0.15625$ \\ 
2 & $\rightarrow$ & $0.3125$ \\ 
3 & $\rightarrow$ & $0.3125$ \\ 
4 & $\rightarrow$ & $0.15625$ \\ 
5 & $\rightarrow$ & $0.03125$ \\ 
\end{tabular} 
\end{center}
\end{column}
\begin{column}{0.7\textwidth}
\begin{center}
\input{img_tikz/tikz_binomial_0}
\end{center}
\end{column}

\end{columns}
\end{frame}



\begin{frame}{Distribución Binomial}
Hablaremos de una distribución binomial cuando:
\begin{itemize}[<+->]
\item Se parte de un experimento compuesto de varios simples independientes
\item Los experimentos simples son dicotómicos. Es decir, solo puede haber dos sucesos elementales: uno al que llamaremos acierto y otro al que llamaremos fracaso
\item Asociado al experimento compuesto tenemos la variable número de aciertos cuando realizamos el experimento simple un número determinado de veces
\end{itemize}
\end{frame}

\begin{frame}{Distribución Binomial}
En la situación anterior, la distribución binomial vendrá determinada por dos parámetros:
\begin{itemize}
\item Parámetro $n$: Número de veces que se realiza el experimento simple 
\item Parámetro $p$: La probabilidad de que ocurra el suceso acierto
\end{itemize}


A este tipo de variable y su distribución de probabilidades se le llama binomial.
\end{frame}

\begin{frame}{Distribución Binomial}
\textbf{Ejemplo:} Así en el ejemplo de las monedas, el experimento se compone de \textbf{5 lanzamientos de moneda}. Si sale cara es acierto y si no fracaso. La variable aleatoria asociada al experimento será el número de caras que salen al lanzar 5 monedas. Esta variable sigue una distribución binomial.


A este tipo de variable y su distribución de probabilidades se le llama binomial.
\end{frame}

\begin{frame}{Probabilidad de la binomial}
\textbf{En general tendremos una binomial de tamaño $n$ y probabilidad $p$}, cuando el experimento simple se haga $n$ veces y la probabilidad de acierto sea $p$.

La función de probabilidad en este caso nos queda:

\begin{block}
 $$P\colon \begin{array}{l} 
          X \rightarrow \mathbb{R} \\ 
          k\mapsto P(X=k)=\binom{n}{k}\left(p\right)^k\cdot  \left(1-p\right)^{n-k} 
         \end{array}$$

\end{block} 
    
\end{frame}

\begin{frame}{Distribución Binomial}
         
\paragraph{Ejemplos:} Representación gráfica de la distribución de probabilidad de algunas binomiales:    
         
\input{img_tikz/tikz_binomial}
    
\end{frame}



\begin{frame}
{Distribución Normal}

Se trata de una distribución asociada a a un variable continua. Tiene dos parámetros:
\begin{itemize} [<+->]
    \item $\mu :$ Media de la distribución
    \item $\sigma :$ Desviación típica
\end{itemize}
Y se denota así: $
X \sim \mathcal{N}(\mu,\,\sigma)\,.
    $ 
\end{frame}

\begin{frame}{Distribución de probabilidades en una variable continua}

La probabilidad total es 1 y la variable $X$ puede tomar $\infty$ valores ($x \in \left(-\infty, +\infty\right)$). Por tanto, en variables continuas la probabilidad de que tome un valor concreto será 0 ($\lim_{x \to \infty}\frac{1}{x}=0$).    

Para calcular las probabilidades no se utilizarán funciones de probabilidad como hemos visto hasta ahora sino \textbf{funciones de densidad}:
\end{frame}

\begin{frame}{Función de densidad}
En variables continuas solo tiene sentido calcular la probabilidad en intervalos.
Se llama \textbf{función de densidad} ($f(x)$) a aquella que: 
\begin{block}{}
$$P\left(a\leq X \leq b \right) = \int_{a}^{b} f(x) dx$$
\end{block}    


La interpretación gráfica de lo anterior nos dice que la probabilidad de un intervalo corresponde con el área de la función de densidad en ese intervalo.
\begin{center}
\input{img_tikz/tikz_densidad_1}

\end{center}
\end{frame}


\begin{frame}{Función de densidad de una distribución normal}  
\begin{columns}
\begin{column}{0.4\textwidth}
\begin{block}{}
Si $
X \sim \mathcal{N}(\mu,\,\sigma)
    $, la función de densidad es:
    $$f(x)=\frac{1}{{\sigma \sqrt {2\pi } }}e^{{{ - \left( {x - \mu } \right)^2 } \mathord{\left/ {\vphantom {{ - \left( {x - \mu } \right)^2 } {2\sigma ^2 }}} \right. \kern-\nulldelimiterspace} {2\sigma ^2 }}}$$
\end{block}
\end{column}
\begin{column}{0.6\textwidth}
\input{img_tikz/tikz_normal}
\end{column}
\end{columns}{}

\end{frame}

\begin{frame}{Cálculo práctico de la probabilidad de la Normal:}
\begin{columns}
\begin{column}{0.4\textwidth}
\begin{block}{}
En realidad, para calcular la probabilidad no se hace la integral, sino que se utiliza una tabla que ya tiene calculadas probabilidades de la  $Z \sim \mathcal{N}(0,\,1)
    $ ...
\end{block}
\end{column}
\begin{column}{0.6\textwidth}
\includegraphics[page=1,width=1\textwidth]{probabilidad/distribucion_normal}
\end{column}
\end{columns}


\end{frame}

\begin{frame}{Cálculo práctico de la probabilidad de la Normal:}
\begin{columns}
\begin{column}{0.6\textwidth}
\begin{block}{}
... y que refleja:

$$P\left(Z\leq k \right), \ \  k \in \left[ 0 , 4'09 \right]$$
\begin{center}
    \input{img_tikz/tikz_normal_z}
\end{center}
\end{block}
\end{column}
\begin{column}{0.4\textwidth}
\includegraphics[page=1,width=1\textwidth]{probabilidad/distribucion_normal}
\end{column}
\end{columns}


\end{frame}

\begin{frame}{Cálculo en la $Z \sim \mathcal{N}(0,\,1)$ o normal estándar}
\begin{itemize} [<+->]
    \item $P\left(Z\leq 0 \right)=0.5 $. Ya que en este caso $k=0=0.00$ la suma del valor de la fila 0 con el valor de la columna 0 me da el valor de $k$, y la probabilidad asociada es $0.5$
    \item $P\left(Z\leq 1.23 \right)= 0.89065$. En este caso la probabilidad asociada a 1.23 se busca en la fila 1.2 y la columna 0.03 
\end{itemize}



\end{frame}

\begin{frame}{Cálculo en $X \sim \mathcal{N}(\mu,\,\sigma)$} 
\begin{block}
    Las probabilidades en conjuntos de valores de la distribución que no se puedan obtener directamente de la tabla se transformarán en operaciones con probabilidades que sí estén en la tabla:
\end{block}
Veamos algunos ejemplos:
\end{frame}


\begin{frame}{Probabilidad condicionada}
\begin{block}{}
$$P(A|B)=\dfrac{P(A\cap B)}{P(B)}$$
\end{block}
Despejando:
$$P(A\cap B) = P(A|B)\cdot P(B)$$

\begin{itemize}[<+->]
\item Se dice que dos sucesos son \textbf{independientes} cuando la probabilidad de cada uno no depende del resultado del otro. 

$$A\ y \ B\ son \ independientes \Longleftrightarrow P(B|A)=P(B)$$

\end{itemize}
\end{frame}

\begin{frame}{Ejemplo sin remplazamiento}
En una urna hay tres bolas blancas y dos negras. Se extraen dos bolas \textbf{sin} reemplazamiento:
\input{img_tikz/tikz_arbol_1}
\begin{itemize}[<+->]
\item Probabilidad de que sean del mismo color: \\
$P((B_1\cap B_2)\cup (N_1\cap N_2))=\frac{3}{10}+\frac{1}{10}=\frac{2}{5}$
\end{itemize}

\end{frame}

\begin{frame}{Ejemplo con remplazamiento}
En una urna hay tres bolas blancas y dos negras. Se extraen dos bolas \textbf{con} reemplazamiento:
\input{img_tikz/tikz_arbol_2}
\begin{itemize}
\item Probabilidad de que sean del mismo color: \\
$P((B_1\cap B_2)\cup (N_1\cap N_2))=\frac{9}{25}+\frac{4}{25}=\frac{13}{25}$
\end{itemize}

\end{frame}



\begin{frame}{Teorema de la probabilidad total}
Si $A_1$, $A_2$, ..., $A_n$   son sucesos incompatibles dos a dos y cuya unión es todo el espacio muestral, entonces la probabilidad de cualquier otro suceso $B$ es:

$$P(B)=\sum_{i=1}^n P(A_i)\cdot  P(B|A_i) $$
\end{frame}

\begin{frame}{Ejemplo de probabilidad total}
En una urna en la que hay tres bolas blancas y dos negras. Si se extraen dos bolas \textbf{sin} reemplazamiento:
\input{img_tikz/tikz_arbol_3}

$$P(B_2)=P(B_1)\cdot P(B_2|B_1) + P(N_1)\cdot P(B_2|N_1)
= \frac{3}{5}\cdot\frac{2}{4} + \frac{2}{5}\cdot\frac{3}{4}$$
\end{frame}


\begin{frame}{Teorema de Bayes}
Si $A_1$, $A_2$, ..., $A_n$   son sucesos incompatibles dos a dos y cuya unión es todo el espacio muestral, y $B$ otro suceso cualquiera:

$$P(A_i|B)=\dfrac{P(A_i \cap B)}{\sum_{i=1}^n P(A_i)\cdot  P(B|A_i)} $$

\end{frame}

\begin{frame}{Ejemplo de Bayes}
En una urna en la que hay tres bolas blancas y dos negras. Si se extraen dos bolas \textbf{sin} reemplazamiento:
\input{img_tikz/tikz_arbol_3}

$$P(B_1|B_2)=\dfrac{P(B_1 \cap B_2)}{P(B_1)\cdot  P(B_2|B_1)+P(N_1)\cdot  P(B_2|N_1)}=\dfrac{\dfrac{3}{5}\cdot\dfrac{2}{4}}{\dfrac{3}{5}\cdot\dfrac{2}{4} + \dfrac{2}{5}\cdot\dfrac{3}{4}}$$
\end{frame}



\end{document}