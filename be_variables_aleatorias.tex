\documentclass[11pt]{beamer}
%\documentclass[11pt,handout]{beamer}
\usetheme{Boadilla}
%\usetheme{metropolis}

\usecolortheme{crane}


\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}

\usepackage{hyperref}
\usepackage{graphicx}
\usepackage[spanish]{babel}
\graphicspath{{./img/}}

\usepackage{pgf,tikz}

\usetikzlibrary{shapes, calc, shapes, arrows, math, babel, positioning}
\newcommand{\degre}{\ensuremath{^\circ}}
\usepackage{pgf,tikz,pgfplots}
\pgfplotsset{compat=1.15}
\usepackage{mathrsfs}
\usetikzlibrary{arrows}

%\author{}
\title{Variables aleatorias}

\setbeamercovered{transparent} 
\setbeamertemplate{navigation symbols}{} 
\logo{} 
%\institute{} 
\date{} 
\author{Dep. de Matemáticas}
%\subject{} 
\titlegraphic{\includegraphics[width=0.2\columnwidth]{header_right}}
\begin{document}

\begin{frame}
\titlepage
\end{frame}

%\begin{frame}
%\tableofcontents
%\end{frame}

\begin{frame}{Variables aleatorias y distribuciones de probabilidad}
\begin{block}{Finalidad:} \textbf{Abstraer matemáticamente} un tipo de \textbf{experimento aleatorio}. Y, con ello, poder estimar de manera teórica lo que sucedería de manera experimental mediante una estadística.
\end{block}

\pause

\begin{block}{¿Cómo?:} Mediante \textbf{variables aleatorias} y \textbf{distribuciones de probabilidad} asociadas a esas variables

\end{block}


\end{frame}

\begin{frame}{Variables aleatorias}
\begin{block}{}
Una \textbf{variable aleatoria} es una función que a cada suceso
elemental de un espacio muestral le asigna un número. \\ Para hacer referencia a las variables se usan las letras: $X$, $Y$, ...
\end{block}
\end{frame}

\begin{frame}{Ejemplo}
\begin{block}{}
Sea el \textbf{experimento aleatorio “lanzar un dado”}El espacio muestral lo componen las 6 caras del dado 
\end{block}
\pause
El espacio muestral lo componen las 6 caras del dado.\\
Podemos asignar la variable $X$ que a cada cara le asocia el número que represente su cara.
\begin{center}
\begin{tabular}{ccc}
 & $X$ &  \\
Suceso &  &  $x_i$\\ \hline 
Cara 1 & $\rightarrow$ & 1 \\ 
Cara 2 & $\rightarrow$ & 2 \\ 
Cara 3 & $\rightarrow$ & 3 \\ 
Cara 4 & $\rightarrow$ & 4 \\ 
Cara 5 & $\rightarrow$ & 5 \\ 
Cara 6 & $\rightarrow$ & 6 \\ 
\end{tabular} 
\end{center}
\end{frame}


\begin{frame}{Ejemplo}
\begin{block}{}
Sea el \textbf{experimento compuesto "lanzar dos monedas"} 
\end{block}
\pause
Podemos asignar la variable aleatoria:
\begin{center}
\emph{Y = \{Número de caras\}} \\
\begin{tabular}{ccc}
 & $Y$ &  \\
Suceso &  &  $y_i$\\ \hline 
C,C & $\rightarrow$ & 2 \\ 
C,X & $\rightarrow$ & 1 \\ 
X,C & $\rightarrow$ & 1 \\ 
X,X & $\rightarrow$ & 0 \\ 
\end{tabular} 
\end{center}
\end{frame}




\begin{frame}{Tipos de variables aleatorias}
\begin{itemize}[<+->]
    \item{Discretas:} Toman un \textbf{número finito o numerable} de valores. \textbf{Ejemplo:} Sea la \emph{X =“El número de caras al lanzar dos dados”}. Los valores posibles son 0, 1 o 2 (que es un conjunto finito de datos, en concreto 3 datos)
\item{Continuas:} Toman valores en un \textbf{rango continuo}. \textbf{Ejemplo:} \emph{X = “Distancia al centro de la diana medida desde la posición en que cae un dardo lanzado por un tirador experto” }. En este caso la variable puede tomar cualquier valor en el rango entre 0 y el radio de la diana 
\end{itemize}

\end{frame}

\begin{frame}{Distribuciones de probabilidad}
\begin{block}{}
Llamaremos \textbf{distribución de probabilidad} a la relación entre los valores de la variable y sus probabilidades.
\end{block}

\begin{itemize}[<+->]
    \item Estas relaciones se pueden indicar mediante el uso de funciones
    \item El tipo de función y su tratamiento es diferente según las variables sean discretas o continuas
    
\end{itemize}


Veamos algunas distribuciones ...
\end{frame}


\begin{frame}
{Distribución uniforme discreta}
\begin{block}{Ejemplo}
Sea la variable \emph{X = “Número obtenido al lanzar una dado”}
\end{block}
\pause
\begin{columns}
\begin{column}{0.5 \textwidth}
A cada valor de la variable podemos asignarle su probabilidad:
\begin{center}
\begin{tabular}{ccc}
 & $P(X)$ &  \\
$x_i$ &  &  $P(x_i)$\\ \hline 
1 & $\rightarrow$ & $\tfrac{1}{6}$ \\ 
2 & $\rightarrow$ & $\tfrac{1}{6}$ \\ 
3 & $\rightarrow$ & $\tfrac{1}{6}$ \\ 
4 & $\rightarrow$ & $\tfrac{1}{6}$ \\ 
5 & $\rightarrow$ & $\tfrac{1}{6}$ \\ 
6 & $\rightarrow$ & $\tfrac{1}{6}$ \\ 
\end{tabular} 
\end{center}
\end{column}
\pause
\begin{column}{0.5 \textwidth}
 Podemos representar la relación anterior mediante una función:

$$P\colon \begin{array}{ll} 
          X \rightarrow \mathbb{R} \\ 
          x_i\mapsto P(X=x_i)=\frac{1}{n} 
         \end{array}$$
\end{column}
\end{columns}

\pause
A este tipo de distribución se le llama \textbf{uniforme discreta}.
\end{frame}

\begin{frame}
{Distribución Binomial. Introducción}
\begin{block}{Ejemplo} Queremos calcular las probabilidades de que al lanzar 5 monedas, obtengamos tres caras.
\end{block}
Un suceso que cumple el enunciado es:
$$S_1=\left\lbrace C,C,C,X,X \right\rbrace$$
Teniendo en cuenta que lanzar cada moneda son experimentos independientes, la probabilidad de ese suceso será:
%$$P\left(S_1\right)=P\left(C_1\right)\cdot P\left(C_2 C_1 \right)$$
\begin{eqnarray*}
P\left(S_1\right) & = &P\left(C_1\right)\cdot P\left(C_2 | C_1 \right)\cdot ... \cdot P\left(X_5 | C_1 \cap C_2  \cap C_3  \cap X_4   \right)= \\ &  = & P\left(C_1\right)\cdot  P\left(C_2\right) \cdot P\left(C_3\right) \cdot P\left(X_4\right) \cdot P\left(X_5\right)= \\
& = & P\left(C\right)^3\cdot  P\left(X\right)^2
\end{eqnarray*}


\end{frame}

\begin{frame}{}
Como la probabilidad de que una moneda sea cara es $\frac{1}{2}$ y la de que sea cruz también:

$$P\left(S_1\right)=\left(\frac{1}{2}\right)^3\cdot  \left(\frac{1}{2}\right)^2$$
Ahora bien, habrá tantos sucesos que cumplan el enunciado como combinaciones de 5 elementos tomados de 3 en 3. Por tanto la probabilidad de que salgan 3 caras será:

$$P\left(Salgan \ 3 \ caras\right)=\binom{5}{3}\left(\frac{1}{2}\right)^3\cdot  \left(\frac{1}{2}\right)^2$$

\end{frame}

\begin{frame}{}

Podemos determinar la probabilidad mediante la siguiente función.

$$P\colon \begin{array}{l} 
          X \rightarrow \mathbb{R} \\ 
          k\mapsto P(X=k)=\binom{5}{k}\left(\frac{1}{2}\right)^k\cdot  \left(\frac{1}{2}\right)^{5-k} 
         \end{array}$$

\end{frame}


\begin{frame}{}
Realizando los cálculos para $k = 1,...,5 $, la distribución de probabilidad de $X$ que resulta es:
\begin{columns}
\begin{column}{0.3\textwidth}
\begin{center}
\begin{tabular}{ccc}
 & $P(X)$ &  \\
$x_i$ &  &  $P(x_i)$\\ \hline 
0 & $\rightarrow$ & $0.03125$ \\ 
1 & $\rightarrow$ & $0.15625$ \\ 
2 & $\rightarrow$ & $0.3125$ \\ 
3 & $\rightarrow$ & $0.3125$ \\ 
4 & $\rightarrow$ & $0.15625$ \\ 
5 & $\rightarrow$ & $0.03125$ \\ 
\end{tabular} 
\end{center}
\end{column}
\begin{column}{0.7\textwidth}
\begin{center}
\input{img_tikz/tikz_binomial_0}
\end{center}
\end{column}

\end{columns}
\pause
Esto es un ejemplo de \textbf{distribución binomial} de tamaño $5$ y probabilidad $0.5$ .
\end{frame}



\begin{frame}{Distribución Binomial}
Hablaremos de una \textbf{distribución binomial} cuando:
\begin{itemize}[<+->]
\item Se parte de un \textbf{experimento compuesto} de varios simples independientes
\item Los experimentos simples son \textbf{dicotómicos}. Es decir, solo puede haber dos sucesos elementales: uno al que llamaremos acierto y otro al que llamaremos fracaso
\item Asociado al experimento compuesto tenemos la variable \textbf{número de aciertos} cuando realizamos el experimento simple un número determinado de veces
\end{itemize}
\end{frame}

\begin{frame}{Distribución Binomial}
En la situación anterior, la distribución binomial vendrá determinada por dos parámetros:
\begin{itemize}[<+->]
\item Parámetro $n$: Número de veces que se realiza el experimento simple 
\item Parámetro $p$: La probabilidad de que ocurra el suceso acierto
\end{itemize}
\pause

A este tipo de variable y su distribución de probabilidades se le llama \textbf{binomial} y se denota $$X \sim \mathcal{B}(n,\,p)$$.
\end{frame}

\begin{frame}{Ejemplo}
\begin{block}{Lanzamineto de 5 monedas} El experimento se compone de \textbf{5 lanzamientos de moneda}. Si sale cara es acierto y si no fracaso. La variable aleatoria asociada al experimento será el número de caras que salen al lanzar 5 monedas. Esta variable sigue una distribución binomial $X \sim \mathcal{B}(5,\,0.5)$.
\end{block}



\end{frame}

\begin{frame}{Probabilidad de la binomial}
\textbf{En general tendremos una binomial de tamaño $n$ y probabilidad $p$}, cuando el experimento simple se haga $n$ veces y la probabilidad de acierto sea $p$.

La función de probabilidad en este caso nos queda:

\begin{block}{}
 $$P\colon \begin{array}{l} 
          X \rightarrow \mathbb{R} \\ 
          k\mapsto P(X=k)=\binom{n}{k}\left(p\right)^k\cdot  \left(1-p\right)^{n-k} 
         \end{array}$$

\end{block} 
    
\end{frame}

\begin{frame}{Distribución Binomial}
Ejemplos de representación gráfica de la distribución de probabilidad de algunas binomiales:    
         
\input{img_tikz/tikz_binomial}
    
\end{frame}


\begin{frame}{Distribución de probabilidades en una variable continua}

La probabilidad total es 1 y la variable $X$ puede tomar $\infty$ valores ($x \in \left(-\infty, +\infty\right)$). Por tanto, en variables continuas la probabilidad de que tome un valor concreto será 0 ($\lim_{x \to \infty}\frac{1}{x}=0$).    

Para calcular las probabilidades no se utilizarán funciones de probabilidad como hemos visto hasta ahora sino \textbf{funciones de densidad}:
\end{frame}

\begin{frame}{Función de densidad}
En variables continuas solo tiene sentido calcular la probabilidad en intervalos.
Se llama \textbf{función de densidad} ($f(x)$) a aquella que: 
\begin{block}{}
$$P\left(a\leq X \leq b \right) = \int_{a}^{b} f(x) dx$$
\end{block}    


La interpretación gráfica de lo anterior nos dice que la probabilidad de un intervalo corresponde con el área de la función de densidad en ese intervalo.
\begin{center}
\input{img_tikz/tikz_densidad_1}

\end{center}
\end{frame}

\begin{frame}
{Distribución Normal}

Se trata de una distribución asociada a a un variable continua . Resulta de aproximar una binomial para valores muy grandes de $n$. 
\begin{block}{} Y se denota: $
X \sim \mathcal{N}(\mu,\,\sigma)\,.
    $ 
\end{block}
\pause
Tiene dos parámetros:
\begin{itemize} [<+->]
    \item $\mu :$ Media de la distribución
    \item $\sigma :$ Desviación típica
\end{itemize}

\pause    
Esta distribución aparece asociada a muchos fenómenos naturales. 
\end{frame}


\begin{frame}{Función de densidad de una distribución normal}  
\begin{columns}
\begin{column}{0.4\textwidth}
\begin{block}{}
Si $
X \sim \mathcal{N}(\mu,\,\sigma)
    $, la función de densidad es:
    $$f(x)=\frac{1}{{\sigma \sqrt {2\pi } }}e^{{{ - \left( {x - \mu } \right)^2 } \mathord{\left/ {\vphantom {{ - \left( {x - \mu } \right)^2 } {2\sigma ^2 }}} \right. \kern-\nulldelimiterspace} {2\sigma ^2 }}}$$
\end{block}
\end{column}
\begin{column}{0.6\textwidth} Ejemplos de gráficas:
\input{img_tikz/tikz_normal}
\end{column}
\end{columns}{}

\end{frame}

\begin{frame}{Cálculo práctico de la probabilidad de la Normal:}
\begin{columns}
\begin{column}{0.4\textwidth}
\begin{block}{}
En realidad, para calcular la probabilidad no se hace la integral, sino que \textbf{se utiliza una tabla} que ya tiene calculadas probabilidades de la  $Z \sim \mathcal{N}(0,\,1)
    $ ...
\end{block}
\end{column}
\begin{column}{0.6\textwidth}
\includegraphics[page=1,width=1\textwidth]{probabilidad/distribucion_normal}
\end{column}
\end{columns}


\end{frame}

\begin{frame}{Cálculo práctico de la probabilidad de la Normal:}
\begin{columns}
\begin{column}{0.6\textwidth}
\begin{block}{}
... y que refleja:

$$P\left(Z\leq k \right), \ \  k \in \left[ 0 , 4'09 \right]$$
\begin{center}
    \input{img_tikz/tikz_normal_z}
\end{center}
\end{block}
\end{column}
\begin{column}{0.4\textwidth}
\includegraphics[page=1,width=1\textwidth]{probabilidad/distribucion_normal}
\end{column}
\end{columns}


\end{frame}

\begin{frame}{Cálculo en la $Z \sim \mathcal{N}(0,\,1)$ o normal estándar}
\includegraphics[page=1,width=0.8\textwidth]{probabilidad/calculonormal.png}
\begin{itemize} [<+->]
    \item $P\left(Z\leq 0 \right)=0.5 $. Ya que en este caso $k=0=0.00$ la suma del valor de la fila 0 con el valor de la columna 0 me da el valor de $k$, y la probabilidad asociada es $0.5$
    \item $P\left(Z\leq 1.23 \right)= 0.89065$. En este caso la probabilidad asociada a 1.23 se busca en la fila 1.2 y la columna 0.03 
\end{itemize}



\end{frame}

\begin{frame}{Cálculo en la $Z \sim \mathcal{N}(0,\,1)$ o normal estándar} 
\begin{block}{}
    Las probabilidades en conjuntos de valores de la distribución que no se puedan obtener directamente de la tabla se transformarán en operaciones con probabilidades que sí estén en la tabla:
\end{block}
Veamos algunos ejemplos:
\end{frame}


\begin{frame}{Cálculo en la $Z \sim \mathcal{N}(0,\,1)$ o normal estándar}
\begin{block}{Ejemplo}
$P\left(Z\geq 1.23 \right)= 1 - P\left(Z\leq 1.23 \right) = 1 - 0.89065= 0.10935$.
\end{block}
Basta fijarse en la relación que hay entre las áreas:
\begin{center}
   \input{img_tikz/tikz_normal_z21} 
\end{center}

\begin{columns}
\begin{column}{0.5\textwidth}
 \input{img_tikz/tikz_normal_z22}
\end{column}
\begin{column}{0.5\textwidth}
 \input{img_tikz/tikz_normal_z23}
\end{column}
\end{columns}
\end{frame}

\begin{frame}{Cálculo en la $Z \sim \mathcal{N}(0,\,1)$ o normal estándar}
\begin{block}{Ejemplo}
$P\left(Z\leq -2.15 \right)=P\left(Z\geq 2.15 \right)=1-P\left(Z\leq 2.15 \right)=1-0.98422=0.01578$.
\end{block}
Basta fijarse en la relación que hay entre las áreas:
\begin{center}
   \input{img_tikz/tikz_normal_z31} 
\end{center}
\end{frame}

\begin{frame}{Cálculo en la $Z \sim \mathcal{N}(0,\,1)$ o normal estándar}
\begin{block}{Ejemplo}
$P\left( -1.3 < Z < 3.1\right)=P\left( Z < 3.1\right)-P\left(  Z < -1.3\right)=
    P\left( Z < 3.1\right) - \left[ 1 - P\left(  Z < 1.3\right) \right]= 0.99903 - 1 + 0.9032 = 0.90223$.
\end{block}
Basta fijarse en la relación que hay entre las áreas:
\begin{center}
   \input{img_tikz/tikz_normal_z41} 
\end{center}

\begin{columns}
\begin{column}{0.5\textwidth}
 \input{img_tikz/tikz_normal_z42}
\end{column}
\begin{column}{0.5\textwidth}
 \input{img_tikz/tikz_normal_z43}
\end{column}
\end{columns}
\end{frame}

\begin{frame}{Cálculo en la $Z \sim \mathcal{N}(0,\,1)$ o normal estándar}
\begin{block}{Cálculo del valor de la variable a partir de la probabilidad}
El uso de la tabla normal nos permite realizar el proceso inverso. Es decir, fijada una probabilidad $Pr$, encontrar el valor de la variable $k$ que cumpla:
$$P(Z<=k)=Pr$$
    \begin{center}
        \input{img_tikz/tikz_normal_z5}
    \end{center}
\end{block}

\end{frame}

\begin{frame}{Ejemplo}

Dada $Z \sim \mathcal{N}(0,\,1)$, calcula el valor de la variable sabiendo que la probabilidad de que tome un valor menor que ese es de un 85\%. 

$$P(Z<=k)=0.85$$
    \begin{center}
        \input{img_tikz/tikz_normal_z6}
    \end{center}

Vamos a la tabla y buscamos los dos valores seguidos de la tabla entre los que se quede el $0.85$ y encontramos:
$$0.84849 < 0.85 < 0.85083 $$
Como queda más cerca del $0.85083$, me quedo con la celda correspondiente a la fila $1$ y columna $0.04$  $\Rightarrow k=1.04$.
\end{frame}

\begin{frame}{Cálculo en $X \sim \mathcal{N}(\mu,\,\sigma)$ - Tipifiación}
Para manejar $X \sim \mathcal{N}(\mu,\,\sigma)$ reduciremos los cálculos a cálculos en la $Z \sim \mathcal{N}(0,\,1)$ a partir de la siguiente propiedad:

\begin{block}{}
$$ Si \  X \sim \mathcal{N}(\mu,\,\sigma) \Rightarrow X^{'}=\frac{X - \mu}{\sigma} \sim \mathcal{N}(0,\,1) $$
\end{block}

\pause

Al proceso de transformar la variable anterior a una $Z\sim \mathcal{N}(0,\,1)$ se denomina \textbf{tipificarla}.


\end{frame}



\begin{frame}{Ejemplos}

\begin{itemize}[<+->]
    \item $X \sim \mathcal{N}(1,\,2) \to P(X<=2.32)=P(X'<=\frac{2.32-1}{2})=P(Z<=0.66)=0.74537$
    \item $X \sim \mathcal{N}(5,\,3) \to P(X<=3.59)=P(X'<=\frac{3.59-5}{3})=P(Z<=-0.47)=1-P(Z<=0.47)=1-0.68082=0.31918$
\end{itemize}
\end{frame}


\end{document}